```
"_all":针对所有字段分词
4.中文分词检索(重点)
前面已经安装了ik中文分词器,这里就不介绍怎么安装了
ik_max_word: 会将文本做最细粒度的拆分
ik_smart: 会做最粗粒度的拆分

4.1先设置mapping
PUT /my_index7
{
 "mappings": {
	"my_type": {
	 "properties": {
		"text": {
		 "type": "text",
		 "analyzer": "ik_max_word"--------------分词方式使用细颗粒
		}
	 }
	}
 }
}
然后检查下当前的这个索引的状况
GET my_index7/_mapping
只有一个字段”text”随便写点东西就可以了

然后插入一批测试数据
POST my_index7/my_type/1
{
  "text":"你喜欢吃什么?桃子还是橘子",
  "analyzer":"ik_max_word"
}

POST my_index7/my_type/2
{
  "text":"苹果其实有很多的品种",
  "analyzer":"ik_max_word"
}

POST my_index7/my_type/3
{
  "text":"一天一个苹果,医生远离我",
  "analyzer":"ik_max_word"
}

POST my_index7/my_type/4
{
  "text":"苹了个果,看你咋吃",
  "analyzer":"ik_max_word"
}
开始测试
GET my_index7/my_type/_search
{
  "query":{
    "match":{
      "text":"苹果"
    }
  }
}
查询结果如下:
{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 0.6931472,
    "hits" : [--------------------------------------------这里都是包含关键词”苹果”的内容
      {
        "_index" : "my_index7",
        "_type" : "my_type",
        "_id" : "2",
        "_score" : 0.6931472,
        "_source" : {
          "text" : "苹果其实有很多的品种",
          "analyzer" : "ik_max_word"
        }
      },
      {
        "_index" : "my_index7",
        "_type" : "my_type",
        "_id" : "3",
        "_score" : 0.2876821,
        "_source" : {
          "text" : "一天一个苹果,医生远离我",
          "analyzer" : "ik_max_word"
        }
      }
    ]
  }
}
测试:输入一些其他的词,和短语看看效果
注意:在当前的这个测试里,如果只输入”你”会发现检索的内容不太一样,有几个数据是没能检索出来的,所以匹配的内容也不是都能检索到的,那么输入的内容如何匹配才是检索的关键,这里只能通过多测试提高关键词的权重来解决实际问题,没有什么更好的办法

4.2使用颗粒度粗的分词
还是先设置mapping
第一步:创建索引
PUT index999
第一步:创建mapping
PUT /index999/fulltext/_mapping
{
  "fulltext": {
    "_all": {
      "analyzer": "ik_smart"
    },
    "properties": {
      "content": {
        "type": "text"
      },
      "title":{
        "type":"text"
      }
    }
  }
}
第三步:插入数据
POST /index999/fulltext/1
{
  "title":"路过面了个试就拿到2个offer。是运气吗",
  "content": "路过随便面个试就拿到2个offer。是运气吗？ #复习很重要#看看面试问的问题，再瞧瞧师兄的学习态度，你就明白 机会为何总与你擦肩而过了。[玫瑰] 以下是我和师兄的聊天记录，你会几个"
}

POST /index999/fulltext/2
{
  "title":"人生没有白走的路，每一步都算数",
  "content": "看了一位新同学的自我介绍，看完后让人沉思，有多少人也跟他一样，不是不想努力，而是一直找不到方向，只能在底层兜兜转转消磨殆尽美好青春年华。 他叫车融，在深圳工作，我去深圳分校时，他正好去咨询，他跟我聊过很多，感觉是个很有想法的人，今天看完他写的这个东西，感觉有些沉重，但人生的路， 每一步都算数，过往的"
}

POST /index999/fulltext/3
{
  "title":"不吹不擂，你想要的Python面试都在这里了【315+道题】",
  "content": "写在前面 近日恰逢学生毕业季，课程后期大家“期待+苦逼”的时刻莫过于每天早上内容回顾和面试题问答部分【临近毕业每天课前用40-60分钟对之前内容回顾、提问和补充，专挑班里不爱说话就的同学回答】。 期待的是可以检验自己学习的成功；苦逼的是怎么又有东西没记住，但我们依然每天坚持一遍、一遍又一遍指导记住为"
}

POST /index999/fulltext/4
{
  "title":"白话tornado源码之褪去模板的外衣",
  "content": "上一篇《白话tornado源码之请求来了》介绍了客户端请求在tornado框架中的生命周期，其本质就是利用epoll和socket来获取并处理请求。在上一篇的内容中，我们只是给客户端返回了简单的字符串，如：“Hello World”，而在实际开发中，需要使用html文件的内容作为模板，然后将被处理后"
}

POST /index999/fulltext/5
{
  "title":"第二篇：白话tornado源码之待请求阶段",
  "content": "上篇《白话tornado源码之一个脚本引发的血案》用上帝视角多整个框架做了一个概述，同时也看清了web框架的的本质，下面我们从tornado程序的起始来分析其源码。概述上图是tornado程序启动以及接收到客户端请求后的整个过程，对于整个过程可以分为两大部分：启动程序阶段，又称为待请求阶段"
}
开始测试:
GET /index999/fulltext/_search
{
  "query": {
    "match": {
      "content": "白话"
    }
  }
}
检索结果就不贴了,这里会看见检索出来的内容跟预想的完全不同,根本就不是咱们要的东西,但是max_score中的数据还是跟设定的关键词有比较强的关联.
GET /index999/fulltext/_search
{
  "query": {
    "match_phrase": {
      "content": "白话"
    }
  }
}
这个时候你再查询就可以看到检索的内容了,后面会详细的讲下几种查询方式
```