### Python Elasticsearch Client
	- Elasticsearch的正式低级客户端。它的目标是为Python中所有与elasticsearch相关的代码提供共同点;正因为如此，它试着不发表任何意见，并且具有很强的可扩展性
### Installation
	- python -m pip install elasticsearch
### Features
	- 该客户端被设计为Elasticsearch的REST API的非常薄的包装，以实现最大的灵活性。这意味着这个客户没有意见;
		这也意味着从Python中使用一些api有点麻烦。
		我们创建了一些帮助程序来帮助解决这个问题，并在此基础上创建了一个更高级的库(Elasticsearch -dsl)，以提供使用Elasticsearch更方便的方式
### Persistent Connections
	- elasticsearch-py在单个连接池内使用持久连接(每个配置或嗅探节点一个)。您可以在两种http协议实现中进行选择。有关更多信息，请参阅传输类
	- 传输层将创建每个节点并选择连接类的一个实例跟踪单个节点的健康——如果一个节点变得反应迟钝(抛出异常,而连接到它)放在一个超时ConnectionPool阶级,只有回到循环超时结束后(或者当没有住节点)。
		默认情况下，节点在传入池之前是随机的，循环策略用于负载平衡。
	- 您可以通过将参数传递给连接层API(将传递给Elasticsearch类的所有关键字参数)来定制此行为。
		如果您想要完成的任务不受支持，您应该能够创建相关组件的子类，并将其作为参数传入，而不是使用默认实现
### Automatic Retries
	- 如果一个节点的连接由于连接问题(引发ConnectionError)而失败，则认为它处于错误状态。它将被暂停，等待dead_timeout秒，请求将在另一个节点上重试。
	- 如果一个连接在一行中失败多次，超时时间将会越来越大，以避免触及按所有指示都已关闭的节点。如果没有可用的实时连接，将使用超时最小的连接。
	- 默认情况下，重试不会被超时触发(ConnectionTimeout)，将retry_on_timeout设置为True，也会在超时时重试
### Sniffing
	- 客户端可以配置为在启动、定期和/或失败时检查集群状态以获得节点列表。有关详细信息，请参阅传输参数
	```
		from elasticsearch import Elasticsearch

		# by default we don't sniff, ever
		es = Elasticsearch()

		# you can specify to sniff on startup to inspect the cluster and load
		# balance across all nodes
		es = Elasticsearch(["seed1", "seed2"], sniff_on_start=True)

		# you can also sniff periodically and/or after failure:
		es = Elasticsearch(["seed1", "seed2"],
				  sniff_on_start=True,
				  sniff_on_connection_fail=True,
				  sniffer_timeout=60)
	```
### Thread safety
	- 客户端是线程安全的，可以在多线程环境中使用。
	- 最佳实践是创建客户机的单个全局实例，并在整个应用程序中使用它。
	- 如果应用程序是长时间运行的，请考虑打开嗅探，以确保客户机在集群位置上是最新的。
	- 默认情况下，我们允许urllib3打开10个连接到每个节点，如果你的应用程序调用更多的并行，使用maxsize参数来提高限制:
	```
		# allow up to 25 connections to each node
		es = Elasticsearch(["host1", "host2"], maxsize=25)
	```
	- 由于我们在整个客户端使用持久连接，这意味着客户端不能很好地容忍fork。
	- 如果应用程序调用多个进程，请确保在调用fork后创建一个新的客户机。
	- 注意，Python的多处理模块使用fork在POSIX系统上创建新进程
### SSL and Authentication
	- 您可以将客户端配置为使用SSL连接到您的elasticsearch集群，包括证书验证和HTTP认证
	```
		from elasticsearch import Elasticsearch

		# you can use RFC-1738 to specify the url
		es = Elasticsearch(['https://user:secret@localhost:443'])

		# ... or specify common parameters as kwargs

		es = Elasticsearch(
			['localhost', 'otherhost'],
			http_auth=('user', 'secret'),
			scheme="https",
			port=443,
		)

		# SSL client authentication using client_cert and client_key

		from ssl import create_default_context

		context = create_default_context(cafile="path/to/cert.pem")
		es = Elasticsearch(
			['localhost', 'otherhost'],
			http_auth=('user', 'secret'),
			scheme="https",
			port=443,
			ssl_context=context,
		)
	```
	- elasticsearch-py不附带默认的根证书集。
	- 要有工作的SSL证书验证，你需要指定你自己的为cafile或capath或cadata，或安装certifi，它将被自动挑选。
	- 有关选项的详细描述，请参阅类Urllib3HttpConnection。
### Connecting via Cloud ID
	- 云ID是配置客户端以使用弹性云部署的一种简单方法。
	- 将cloud_id与http_auth或api_key结合起来，就可以通过弹性云部署进行身份验证。
	- 使用cloud_id默认启用TLS验证和HTTP压缩，并将端口设置为443，除非通过端口参数或cloud_id中编码的端口值被覆盖。使用云ID也会禁用嗅探。
	```
	from elasticsearch import Elasticsearch

	es = Elasticsearch(
		cloud_id="cluster-1:dXMa5Fx...",
		http_auth=("elastic", "<password>"),
	)
	```
### API Key Authentication
	- 您可以将客户机配置为使用Elasticsearch的API键连接到您的集群。请注意，这种身份验证方法是在Elasticsearch 6.7.0版本中引入的
	```
		from elasticsearch import Elasticsearch

		# you can use the api key tuple es = Elasticsearch(

		[‘node-1’, ‘node-2’, ‘node-3’], api_key=(‘id’, ‘api_key’),
		)

		# or you pass the base 64 encoded token es = Elasticsearch(

		[‘node-1’, ‘node-2’, ‘node-3’], api_key=’base64encoded tuple’,
		)
	```
### Logging
	-elasticsearch-py使用来自python的标准日志库定义两个日志记录器:elasticsearch和elasticsearch.trace。
	- 根据日志级别的不同，客户端使用elasticsearch来记录标准活动。elasticsearch跟踪可用于以curl命令的形式将请求记录到服务器，并使用打印精美的json，然后可以从命令行执行该命令。
	- 因为它被设计为共享的(例如，为了演示一个问题)，它还仅仅使用localhost:9200作为地址，而不是主机的实际地址。如果跟踪日志记录器还没有配置，那么已经配置好了
### Environment considerations
	- 在使用客户机时，您的环境可能会有一些限制。
	- 当使用HTTP负载均衡器时，您不能使用嗅探功能——集群将为客户端提供IP地址以直接连接到集群，从而绕过负载均衡器。根据您的配置，这可能是您不想要的东西或完全破坏。
	- 在某些环境中(特别是在谷歌应用程序引擎上)，您的HTTP请求可能会受到限制，因此GET请求不会接受body。在这种情况下，使用传输的send_get_body_as参数发送所有
	```
		from elasticsearch import Elasticsearch
		es = Elasticsearch(send_get_body_as='POST')
	```
### Compression
	- 当使用容量受限的网络(低吞吐量)时，启用压缩可能很方便。这在进行批量加载或插入大型文档时特别有用。这将配置压缩
	```
		from elasticsearch import Elasticsearch
		es = Elasticsearch(hosts, http_compress=True)
	```
	- Compression is enabled by default when connecting to Elastic Cloud via cloud_id.
### Running on AWS with IAM
	```
		If you want to use this client with IAM based authentication on AWS you can use the requests-aws4auth package:

		from elasticsearch import Elasticsearch, RequestsHttpConnection
		from requests_aws4auth import AWS4Auth

		host = 'YOURHOST.us-east-1.es.amazonaws.com'
		awsauth = AWS4Auth(YOUR_ACCESS_KEY, YOUR_SECRET_KEY, REGION, 'es')

		es = Elasticsearch(
			hosts=[{'host': host, 'port': 443}],
			http_auth=awsauth,
			use_ssl=True,
			verify_certs=True,
			connection_class=RequestsHttpConnection
		)
		print(es.info())
	```
### Customization
	```
		By default, JSONSerializer is used to encode all outgoing requests. However, you can implement your own custom serializer

		from elasticsearch.serializer import JSONSerializer

		class SetEncoder(JSONSerializer):
			def default(self, obj):
				if isinstance(obj, set):
					return list(obj)
				if isinstance(obj, Something):
					return 'CustomSomethingRepresentation'
				return JSONSerializer.default(self, obj)

		es = Elasticsearch(serializer=SetEncoder())
	```
### Elasticsearch-DSL
	```
		用于范围更有限的更高级的客户端库, 看一下elasticsearch-dsl - 在elasticsearch-py之上的一个更符合python风格的库.
		Elasticsearch - DSL通过映射Elasticsearch JSON DSL的术语和结构，同时直接使用定义的类或类似查询集的表达式从Python公开整个DSL范围，从而提供了一种更方便和惯用的方式来编写和操作查询。		
		它还提供了一个可选的持久层，用于以类似orm的方式将文档作为Python对象使用:定义映射, 检索和保存文档，包装文档数据 in user-defined classes.
	```

